{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_sample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgyqbn9FKFqG",
        "colab_type": "code",
        "outputId": "438aa3e1-2c4b-4753-9d9d-6e51d1a89a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import preprocessing\n",
        "from keras.layers import Input, Dense, Activation, Flatten, Dropout, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fv3S2liGvfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = datasets.load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6NFCJMUG4Lv",
        "colab_type": "code",
        "outputId": "e960d8a2-dda7-4c97-e699-ec1318fa5070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "iris.keys()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiFBR-mbHmTJ",
        "colab_type": "code",
        "outputId": "08992aa5-7f0f-44cb-ab4d-9d09969b52f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(iris['target_names'])\n",
        "print(iris['feature_names'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df-Vv4o5H5G0",
        "colab_type": "code",
        "outputId": "451c9023-6758-43fa-f2b4-238c025f5c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "iris_targets  = iris['target']\n",
        "iris_features = iris['data']\n",
        "print(iris_features.shape)\n",
        "print(iris_targets .shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n",
            "(150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5Prj5lF45O2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(iris_features, iris_targets, train_size=0.8, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKTStwcCLX03",
        "colab_type": "code",
        "outputId": "235a325e-0d61-4127-f68b-afcdc955529f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# one hot\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 3)\n",
            "(30, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgC9FmP0PjqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 正規化\n",
        "x_train = preprocessing.minmax_scale(x_train)\n",
        "x_test = preprocessing.minmax_scale(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHSrna4WwOI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = x_train.shape[1]\n",
        "output_dim = y_train.shape[1]\n",
        "\n",
        "batch_size = 20\n",
        "epochs = 80"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTAcFkgEwKpg",
        "colab_type": "code",
        "outputId": "3c841764-dd35-47b5-c12a-727e90572fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "inputs = Input(shape=(input_dim,))\n",
        "x = inputs\n",
        "\n",
        "x = Dense(64)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dense(8)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = Dense(output_dim)(x)\n",
        "predictions = Activation('softmax')(x)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELi4Cpdnw-Z1",
        "colab_type": "code",
        "outputId": "36c081f9-807b-4017-e817-a2fe81111b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        }
      },
      "source": [
        "model = Model(input=inputs, output=predictions)\n",
        "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 520       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 27        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 1,155\n",
            "Trainable params: 1,011\n",
            "Non-trainable params: 144\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzPbGZ3ZxYa4",
        "colab_type": "code",
        "outputId": "db5c453a-025e-4790-d521-525023554bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(\n",
        "    x = x_train, \n",
        "    y = y_train,\n",
        "    batch_size = batch_size,\n",
        "    epochs = epochs, \n",
        "    validation_split=0.2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 96 samples, validate on 24 samples\n",
            "Epoch 1/80\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "96/96 [==============================] - 2s 16ms/step - loss: 1.4177 - acc: 0.5417 - val_loss: 1.4962 - val_acc: 0.5000\n",
            "Epoch 2/80\n",
            "96/96 [==============================] - 0s 393us/step - loss: 1.1970 - acc: 0.5625 - val_loss: 1.3919 - val_acc: 0.5417\n",
            "Epoch 3/80\n",
            "96/96 [==============================] - 0s 380us/step - loss: 1.0390 - acc: 0.6146 - val_loss: 1.3196 - val_acc: 0.5417\n",
            "Epoch 4/80\n",
            "96/96 [==============================] - 0s 362us/step - loss: 0.9711 - acc: 0.6042 - val_loss: 1.2568 - val_acc: 0.5417\n",
            "Epoch 5/80\n",
            "96/96 [==============================] - 0s 397us/step - loss: 0.9152 - acc: 0.6042 - val_loss: 1.2137 - val_acc: 0.5417\n",
            "Epoch 6/80\n",
            "96/96 [==============================] - 0s 368us/step - loss: 0.8243 - acc: 0.6563 - val_loss: 1.1650 - val_acc: 0.5417\n",
            "Epoch 7/80\n",
            "96/96 [==============================] - 0s 343us/step - loss: 0.7560 - acc: 0.6563 - val_loss: 1.1218 - val_acc: 0.5417\n",
            "Epoch 8/80\n",
            "96/96 [==============================] - 0s 383us/step - loss: 0.7353 - acc: 0.6458 - val_loss: 1.0823 - val_acc: 0.5417\n",
            "Epoch 9/80\n",
            "96/96 [==============================] - 0s 374us/step - loss: 0.7324 - acc: 0.7083 - val_loss: 1.0414 - val_acc: 0.5417\n",
            "Epoch 10/80\n",
            "96/96 [==============================] - 0s 376us/step - loss: 0.6596 - acc: 0.7396 - val_loss: 1.0024 - val_acc: 0.5417\n",
            "Epoch 11/80\n",
            "96/96 [==============================] - 0s 393us/step - loss: 0.6987 - acc: 0.7500 - val_loss: 0.9605 - val_acc: 0.5417\n",
            "Epoch 12/80\n",
            "96/96 [==============================] - 0s 407us/step - loss: 0.6312 - acc: 0.8333 - val_loss: 0.9209 - val_acc: 0.5833\n",
            "Epoch 13/80\n",
            "96/96 [==============================] - 0s 379us/step - loss: 0.6129 - acc: 0.8750 - val_loss: 0.8839 - val_acc: 0.5833\n",
            "Epoch 14/80\n",
            "96/96 [==============================] - 0s 399us/step - loss: 0.5813 - acc: 0.9167 - val_loss: 0.8478 - val_acc: 0.5833\n",
            "Epoch 15/80\n",
            "96/96 [==============================] - 0s 447us/step - loss: 0.5983 - acc: 0.9063 - val_loss: 0.8106 - val_acc: 0.5833\n",
            "Epoch 16/80\n",
            "96/96 [==============================] - 0s 374us/step - loss: 0.5455 - acc: 0.9271 - val_loss: 0.7899 - val_acc: 0.6250\n",
            "Epoch 17/80\n",
            "96/96 [==============================] - 0s 435us/step - loss: 0.6217 - acc: 0.8333 - val_loss: 0.7655 - val_acc: 0.6667\n",
            "Epoch 18/80\n",
            "96/96 [==============================] - 0s 453us/step - loss: 0.5567 - acc: 0.9062 - val_loss: 0.7328 - val_acc: 0.7083\n",
            "Epoch 19/80\n",
            "96/96 [==============================] - 0s 368us/step - loss: 0.5124 - acc: 0.9167 - val_loss: 0.6951 - val_acc: 0.7083\n",
            "Epoch 20/80\n",
            "96/96 [==============================] - 0s 410us/step - loss: 0.5136 - acc: 0.9167 - val_loss: 0.6671 - val_acc: 0.7500\n",
            "Epoch 21/80\n",
            "96/96 [==============================] - 0s 460us/step - loss: 0.5104 - acc: 0.8958 - val_loss: 0.6466 - val_acc: 0.7917\n",
            "Epoch 22/80\n",
            "96/96 [==============================] - 0s 359us/step - loss: 0.4319 - acc: 0.9583 - val_loss: 0.6378 - val_acc: 0.7917\n",
            "Epoch 23/80\n",
            "96/96 [==============================] - 0s 368us/step - loss: 0.4262 - acc: 0.9583 - val_loss: 0.6255 - val_acc: 0.7917\n",
            "Epoch 24/80\n",
            "96/96 [==============================] - 0s 332us/step - loss: 0.4454 - acc: 0.9167 - val_loss: 0.6041 - val_acc: 0.7917\n",
            "Epoch 25/80\n",
            "96/96 [==============================] - 0s 347us/step - loss: 0.4585 - acc: 0.9271 - val_loss: 0.5824 - val_acc: 0.8333\n",
            "Epoch 26/80\n",
            "96/96 [==============================] - 0s 385us/step - loss: 0.4197 - acc: 0.9583 - val_loss: 0.5592 - val_acc: 0.8333\n",
            "Epoch 27/80\n",
            "96/96 [==============================] - 0s 381us/step - loss: 0.4086 - acc: 0.9583 - val_loss: 0.5377 - val_acc: 0.8750\n",
            "Epoch 28/80\n",
            "96/96 [==============================] - 0s 402us/step - loss: 0.3781 - acc: 0.9792 - val_loss: 0.5192 - val_acc: 0.8750\n",
            "Epoch 29/80\n",
            "96/96 [==============================] - 0s 344us/step - loss: 0.4035 - acc: 0.9375 - val_loss: 0.5019 - val_acc: 0.8750\n",
            "Epoch 30/80\n",
            "96/96 [==============================] - 0s 426us/step - loss: 0.4115 - acc: 0.9375 - val_loss: 0.4741 - val_acc: 0.8750\n",
            "Epoch 31/80\n",
            "96/96 [==============================] - 0s 379us/step - loss: 0.3586 - acc: 0.9687 - val_loss: 0.4546 - val_acc: 0.8750\n",
            "Epoch 32/80\n",
            "96/96 [==============================] - 0s 380us/step - loss: 0.3365 - acc: 0.9792 - val_loss: 0.4327 - val_acc: 0.9167\n",
            "Epoch 33/80\n",
            "96/96 [==============================] - 0s 383us/step - loss: 0.3443 - acc: 0.9687 - val_loss: 0.4331 - val_acc: 0.8750\n",
            "Epoch 34/80\n",
            "96/96 [==============================] - 0s 368us/step - loss: 0.3824 - acc: 0.9375 - val_loss: 0.4390 - val_acc: 0.8750\n",
            "Epoch 35/80\n",
            "96/96 [==============================] - 0s 358us/step - loss: 0.3597 - acc: 0.9479 - val_loss: 0.4283 - val_acc: 0.8750\n",
            "Epoch 36/80\n",
            "96/96 [==============================] - 0s 414us/step - loss: 0.3335 - acc: 0.9583 - val_loss: 0.4086 - val_acc: 0.8750\n",
            "Epoch 37/80\n",
            "96/96 [==============================] - 0s 359us/step - loss: 0.3536 - acc: 0.9687 - val_loss: 0.3960 - val_acc: 0.9167\n",
            "Epoch 38/80\n",
            "96/96 [==============================] - 0s 397us/step - loss: 0.2959 - acc: 0.9583 - val_loss: 0.3785 - val_acc: 0.9167\n",
            "Epoch 39/80\n",
            "96/96 [==============================] - 0s 380us/step - loss: 0.2948 - acc: 0.9688 - val_loss: 0.3740 - val_acc: 0.9167\n",
            "Epoch 40/80\n",
            "96/96 [==============================] - 0s 369us/step - loss: 0.2541 - acc: 0.9896 - val_loss: 0.3690 - val_acc: 0.9167\n",
            "Epoch 41/80\n",
            "96/96 [==============================] - 0s 375us/step - loss: 0.2922 - acc: 0.9583 - val_loss: 0.3694 - val_acc: 0.9167\n",
            "Epoch 42/80\n",
            "96/96 [==============================] - 0s 342us/step - loss: 0.3097 - acc: 0.9375 - val_loss: 0.3637 - val_acc: 0.9167\n",
            "Epoch 43/80\n",
            "96/96 [==============================] - 0s 376us/step - loss: 0.2869 - acc: 0.9583 - val_loss: 0.3469 - val_acc: 0.9167\n",
            "Epoch 44/80\n",
            "96/96 [==============================] - 0s 318us/step - loss: 0.2643 - acc: 0.9687 - val_loss: 0.3369 - val_acc: 0.9167\n",
            "Epoch 45/80\n",
            "96/96 [==============================] - 0s 327us/step - loss: 0.2579 - acc: 0.9687 - val_loss: 0.3208 - val_acc: 0.9167\n",
            "Epoch 46/80\n",
            "96/96 [==============================] - 0s 331us/step - loss: 0.2649 - acc: 0.9583 - val_loss: 0.3170 - val_acc: 0.9167\n",
            "Epoch 47/80\n",
            "96/96 [==============================] - 0s 378us/step - loss: 0.2270 - acc: 0.9792 - val_loss: 0.3120 - val_acc: 0.9167\n",
            "Epoch 48/80\n",
            "96/96 [==============================] - 0s 341us/step - loss: 0.2243 - acc: 0.9792 - val_loss: 0.3065 - val_acc: 0.9167\n",
            "Epoch 49/80\n",
            "96/96 [==============================] - 0s 410us/step - loss: 0.3560 - acc: 0.9063 - val_loss: 0.2943 - val_acc: 0.9167\n",
            "Epoch 50/80\n",
            "96/96 [==============================] - 0s 421us/step - loss: 0.2763 - acc: 0.9375 - val_loss: 0.2823 - val_acc: 0.9167\n",
            "Epoch 51/80\n",
            "96/96 [==============================] - 0s 342us/step - loss: 0.1991 - acc: 0.9792 - val_loss: 0.2756 - val_acc: 0.9167\n",
            "Epoch 52/80\n",
            "96/96 [==============================] - 0s 427us/step - loss: 0.1954 - acc: 0.9896 - val_loss: 0.2748 - val_acc: 0.9167\n",
            "Epoch 53/80\n",
            "96/96 [==============================] - 0s 347us/step - loss: 0.1881 - acc: 0.9896 - val_loss: 0.2715 - val_acc: 0.9167\n",
            "Epoch 54/80\n",
            "96/96 [==============================] - 0s 370us/step - loss: 0.2659 - acc: 0.9375 - val_loss: 0.2737 - val_acc: 0.9167\n",
            "Epoch 55/80\n",
            "96/96 [==============================] - 0s 344us/step - loss: 0.1847 - acc: 0.9792 - val_loss: 0.2734 - val_acc: 0.9167\n",
            "Epoch 56/80\n",
            "96/96 [==============================] - 0s 351us/step - loss: 0.2037 - acc: 0.9479 - val_loss: 0.2668 - val_acc: 0.9167\n",
            "Epoch 57/80\n",
            "96/96 [==============================] - 0s 352us/step - loss: 0.1842 - acc: 0.9792 - val_loss: 0.2594 - val_acc: 0.9167\n",
            "Epoch 58/80\n",
            "96/96 [==============================] - 0s 437us/step - loss: 0.1793 - acc: 0.9896 - val_loss: 0.2639 - val_acc: 0.9167\n",
            "Epoch 59/80\n",
            "96/96 [==============================] - 0s 354us/step - loss: 0.2122 - acc: 0.9583 - val_loss: 0.2523 - val_acc: 0.9167\n",
            "Epoch 60/80\n",
            "96/96 [==============================] - 0s 384us/step - loss: 0.3133 - acc: 0.9062 - val_loss: 0.2370 - val_acc: 0.9167\n",
            "Epoch 61/80\n",
            "96/96 [==============================] - 0s 341us/step - loss: 0.1873 - acc: 1.0000 - val_loss: 0.2140 - val_acc: 0.9583\n",
            "Epoch 62/80\n",
            "96/96 [==============================] - 0s 350us/step - loss: 0.2056 - acc: 0.9583 - val_loss: 0.2029 - val_acc: 0.9583\n",
            "Epoch 63/80\n",
            "96/96 [==============================] - 0s 407us/step - loss: 0.2068 - acc: 0.9479 - val_loss: 0.1917 - val_acc: 0.9583\n",
            "Epoch 64/80\n",
            "96/96 [==============================] - 0s 355us/step - loss: 0.4503 - acc: 0.8125 - val_loss: 0.1844 - val_acc: 0.9583\n",
            "Epoch 65/80\n",
            "96/96 [==============================] - 0s 389us/step - loss: 0.1865 - acc: 0.9792 - val_loss: 0.1863 - val_acc: 0.9583\n",
            "Epoch 66/80\n",
            "96/96 [==============================] - 0s 352us/step - loss: 0.2508 - acc: 0.9271 - val_loss: 0.1922 - val_acc: 0.9583\n",
            "Epoch 67/80\n",
            "96/96 [==============================] - 0s 365us/step - loss: 0.1933 - acc: 0.9583 - val_loss: 0.2002 - val_acc: 0.9583\n",
            "Epoch 68/80\n",
            "96/96 [==============================] - 0s 389us/step - loss: 0.1635 - acc: 0.9896 - val_loss: 0.2106 - val_acc: 0.9583\n",
            "Epoch 69/80\n",
            "96/96 [==============================] - 0s 319us/step - loss: 0.3277 - acc: 0.8958 - val_loss: 0.2016 - val_acc: 0.9583\n",
            "Epoch 70/80\n",
            "96/96 [==============================] - 0s 330us/step - loss: 0.1948 - acc: 0.9583 - val_loss: 0.1835 - val_acc: 1.0000\n",
            "Epoch 71/80\n",
            "96/96 [==============================] - 0s 335us/step - loss: 0.2328 - acc: 0.9583 - val_loss: 0.1766 - val_acc: 0.9583\n",
            "Epoch 72/80\n",
            "96/96 [==============================] - 0s 337us/step - loss: 0.1737 - acc: 0.9792 - val_loss: 0.1705 - val_acc: 1.0000\n",
            "Epoch 73/80\n",
            "96/96 [==============================] - 0s 373us/step - loss: 0.1814 - acc: 0.9583 - val_loss: 0.1748 - val_acc: 1.0000\n",
            "Epoch 74/80\n",
            "96/96 [==============================] - 0s 423us/step - loss: 0.1577 - acc: 0.9583 - val_loss: 0.1928 - val_acc: 1.0000\n",
            "Epoch 75/80\n",
            "96/96 [==============================] - 0s 342us/step - loss: 0.1185 - acc: 0.9896 - val_loss: 0.2017 - val_acc: 0.9583\n",
            "Epoch 76/80\n",
            "96/96 [==============================] - 0s 326us/step - loss: 0.1559 - acc: 0.9896 - val_loss: 0.2031 - val_acc: 0.9583\n",
            "Epoch 77/80\n",
            "96/96 [==============================] - 0s 349us/step - loss: 0.2139 - acc: 0.9271 - val_loss: 0.1919 - val_acc: 1.0000\n",
            "Epoch 78/80\n",
            "96/96 [==============================] - 0s 558us/step - loss: 0.2755 - acc: 0.9271 - val_loss: 0.1784 - val_acc: 0.9167\n",
            "Epoch 79/80\n",
            "96/96 [==============================] - 0s 430us/step - loss: 0.1286 - acc: 0.9792 - val_loss: 0.1892 - val_acc: 0.9167\n",
            "Epoch 80/80\n",
            "96/96 [==============================] - 0s 337us/step - loss: 0.1708 - acc: 0.9583 - val_loss: 0.1958 - val_acc: 0.9167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCYbU108xwG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_TV(history):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(loss))\n",
        "\n",
        "    plt.plot(epochs, loss, 'bo' ,label = 'training loss')\n",
        "    plt.plot(epochs, val_loss, 'b' , label= 'validation loss')\n",
        "    plt.title('Training and Validation loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6FodEQSx7Ne",
        "colab_type": "code",
        "outputId": "ebf0b50d-906e-4dca-c256-a8f7e3a74496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "compare_TV(history)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZRU1bXA4d+maSCNiIwRge5GRQUa\npAEJBBUHVEAccMSAwQFR1DyNhoiioigao0FDHAjxOYJTEBWnhxNEMRJlVAE1KDMiDQoy08B+f5wq\nKIqap1tdtb+1anXXrVv37q6CXafOPWcfUVWMMcZUfdW8DsAYY0xqWEI3xpgcYQndGGNyhCV0Y4zJ\nEZbQjTEmR1hCN8aYHGEJ3YQkIgUisklEilO5r5dE5HARScs43eBji8g7ItI/HXGIyG0iMjbR50c4\n7iARmZbq45rMsYSeI3wJ1X/bLSJbA+6HTCyRqOouVT1AVZelct9sJSLvicjtIbafKyIrRaQgnuOp\n6qmqOiEFcfUQkSVBx75LVa9K9tgm91hCzxG+hHqAqh4ALAPOCNi2X2IRkeqZjzKrPQ1cHGL7xcB4\nVd2V4XiMiZsl9DwhIneLyIsi8ryIbAQGiEhXEZkhIutF5HsRGSMihb79q4uIikip7/543+Nvi8hG\nEflERFrEu6/v8V4i8o2IbBCRv4nIxyJySZi4Y4nxShFZJCI/iciYgOcWiMiDIrJORL4DekZ4iSYB\nB4vIrwOe3wDoDTzju3+miMwVkZ9FZJmI3Bbh9Z7u/5uixeHr6ljoe62+FZFBvu11gdeB4oBvW419\n7+VTAc/vKyLzfa/RByJyZMBjK0TkBhH5wvd6Py8iNSO8DoFxHSsiM33P+1REfhXw2OUissQX83ci\n0s+3/QgR+dD3nLUi8lws5zIpoqp2y7EbsAToEbTtbmAHcAbug/wXwDHAr4DqwKHAN8C1vv2rAwqU\n+u6PB9YCnYBC4EVcyzXefRsDG4GzfI/dAFQCl4T5W2KJ8TWgLlAK/Oj/24FrgflAM6AB8KH7Jx/2\ndXsSGBtw/xpgZsD9k4A2vtfvaN/f2Mf32OGBxwam+/+maHH43pNDAfGdYyvQzvdYD2BJiPfyKd/v\nrYBNvucVArcAXwOFvsdXADOAg33n/gYYFObvHwRM8/3eENgAXOR7nS8G1gH1gAN9j7X07dsEaO37\n/Z/ATb7XqBbQzev/D/l0sxZ6fpmuqq+r6m5V3aqqn6nqf1R1p6p+B4wDukd4/kRVnamqlcAEoH0C\n+/YB5qrqa77HHsQlxpBijPFeVd2gqkuAaQHnugB4UFVXqOo64E8R4gXX7XJBQAv2t75t/lg+UNX5\nvtdvHvBCiFhCiRiH7z35Tp0PgPeB42I4LkA/YLIvtkrfseviPgT9HlLV1b5zv0Hk983vDGC+qj7v\ne+2fBb4DTveHDZSJSC1V/V5VF/i2V+I+WJuo6jZV/TjGv8OkgCX0/LI88I6IHCUib4rIahH5GRiJ\na5mFszrg9y3AAQnse0hgHKqquFZkSDHGGNO5gKUR4gX4F/AzcIaIHAGUA88HxNJVRKaJSIWIbMC1\naCO9Xn4R4xCRPiLyHxH5UUTWA6fGeFz/sfccT1V3417PpgH7xPO+hTxuQNxNVfVnXMv9GmC1iLzh\ne70AbsR9U5jp6+YZGOPfYVLAEnp+CR4q93fgS+BwVT0QuB33tT+dvsd1PQAgIsK+ySdYMjF+DzQP\nuB9xWKXvw+UZXMv8YuAtVQ389vAC8DLQXFXrAo/HGEvYOETkF8BE4F7gl6p6EPBOwHGjDW9cBZQE\nHK8a7vVdGUNcMR/Xp9h/XFV9W1V74LpbFuHeJ3yt9UGq2gSX8McFXj8x6WUJPb/VwfWFbhaRVsCV\nGTjnG0AHETlD3Eib64BGaYrxJeB6EWnqu8B5UwzPeQZ30fIyArpbAmL5UVW3iUgXXHdHsnHUBGoA\nFcAuEekDnBzw+A9AQxGpE+HYZ4rICb6LxUNx1yj+E2Ns4bwBtBGRC30Xn3+Du07wpog08b1/Rbjr\nMpuB3QAicoGI+D+g1+M+kGyEUIZYQs9vNwIDcQng77iLl2mlqj8AFwKjcRfZDgPmANvTEONjuP7o\nL4DPcC3haPEtAj7FJdo3gx4eAtwrbpTQLbhkmlQcqroe+D3wCu6C7nm4ZOp//Evct4IlvlEsjYPi\nnY97fR7DfSj0BM709acnTFUrgDNxHz7rfDH2UdWfgALcB8f3vsd+jWuNg+u7/0xENuNGDl2jVXh+\nQlUj7lumMd4QN2FnFXCeqn7kdTzGVGXWQjcZJyI9ReQg32iS23AjIz71OCxjqjxL6MYLx+KGwFUA\npwF9VTVcl4sxJkbW5WKMMTnCWujGGJMjPCvQ1LBhQy0tLfXq9MYYUyXNmjVrraqGHOrrWUIvLS1l\n5syZXp3eGGOqJBEJO+PZulyMMSZHWEI3xpgcYQndGGNyhK1aY0weqaysZMWKFWzbts3rUEwUtWrV\nolmzZhQWFsb8HEvoxuSRFStWUKdOHUpLS3GFLk02UlXWrVvHihUraNEi9mKV1uViTB7Ztm0bDRo0\nsGSe5USEBg0axP1NyhK6MXnGknnVkMj7VOUS+pdfwo03wtatXkdijDHZpcol9KVLYfRo+OQTryMx\nxsRr/fr1PProowk9t3fv3qxfvz7iPrfffjvvvfdeQscPVlpaytq1YZe7zUpVLqEfdxwUFMAHH3gd\niTG5b8IEKC2FatXczwkTkjtepIS+c+fOiM996623OOiggyLuM3LkSHr06JFwfFVdlUvoBx4IxxwD\nU6d6HYkxuW3CBBg82H0rVnU/Bw9OLqkPGzaMb7/9lvbt2zN06FCmTZvGcccdx5lnnknr1q0BOPvs\ns+nYsSNt2rRh3Lhxe57rbzEvWbKEVq1accUVV9CmTRtOPfVUtvr6YC+55BImTpy4Z/8RI0bQoUMH\n2rZty1dffQVARUUFp5xyCm3atGHQoEGUlJREbYmPHj2asrIyysrKeOihhwDYvHkzp59+OkcffTRl\nZWW8+OKLe/7G1q1b065dO/7whz8k/mIlQlU9uXXs2FETdcstqtWrq/78c8KHMCYvLViwIOZ9S0pU\nXSrf91ZSkvj5Fy9erG3atNlzf+rUqVpUVKTffffdnm3r1q1TVdUtW7ZomzZtdO3atb54SrSiokIX\nL16sBQUFOmfOHFVVPf/88/XZZ59VVdWBAwfqP//5zz37jxkzRlVVH3nkEb388stVVfWaa67Re+65\nR1VV3377bQW0oqIixN/vzjdz5kwtKyvTTZs26caNG7V169Y6e/ZsnThxog4aNGjP/uvXr9e1a9fq\nEUccobt371ZV1Z9++inxF0tDv1/ATA2TV6tcCx3gpJNg506YPt3rSIzJXcvCrAQabnuiOnfuvM9Y\n6zFjxnD00UfTpUsXli9fzn//+9/9ntOiRQvat28PQMeOHVmyZEnIY59zzjn77TN9+nT69XPre/fs\n2ZN69epFjG/69On07duX2rVrc8ABB3DOOefw0Ucf0bZtW959911uuukmPvroI+rWrUvdunWpVasW\nl19+OZMmTaKoqCjelyMpVTKh//rXUKOG9aMbk07FxfFtT1Tt2rX3/D5t2jTee+89PvnkE+bNm0d5\neXnIsdg1a9bc83tBQUHY/nf/fpH2SdQRRxzB7Nmzadu2LbfeeisjR46kevXqfPrpp5x33nm88cYb\n9OzZM6XnjKZKJvRf/AK6drWEbkw6jRoFwQ3MoiK3PVF16tRh48aNYR/fsGED9erVo6ioiK+++ooZ\nM2YkfrIwunXrxksvvQTAO++8w08//RRx/+OOO45XX32VLVu2sHnzZl555RWOO+44Vq1aRVFREQMG\nDGDo0KHMnj2bTZs2sWHDBnr37s2DDz7IvHnzUh5/JFV26v9JJ8Edd8CPP0L9+l5HY0zu6d/f/Rw+\n3HWzFBe7ZO7fnogGDRrQrVs3ysrK6NWrF6effvo+j/fs2ZOxY8fSqlUrjjzySLp06ZLEXxDaiBEj\nuOiii3j22Wfp2rUrBx98MHXq1Am7f4cOHbjkkkvo3LkzAIMGDaK8vJwpU6YwdOhQqlWrRmFhIY89\n9hgbN27krLPOYtu2bagqo0ePTnn8kXi2pminTp00mQUupk93QxgnTYK+fVMYmDE5bOHChbRq1crr\nMDy1fft2CgoKqF69Op988glDhgxh7ty5XocVUqj3S0RmqWqnUPtXqRb6hAl7WwvNm0PNmq7bxRK6\nMSZWy5Yt44ILLmD37t3UqFGDf/zjH16HlDJVJqH7x8Ru2eLuL1vmJju88gr87W/exmaMqTpatmzJ\nnDlzvA4jLaJeFBWRJ0RkjYh8GWW/Y0Rkp4icl7rw9ho+fG8y99u9G1auhNWr03FGY4ypWmIZ5fIU\nEHHsjYgUAPcB76QgppAijX21WaPGGBNDQlfVD4Efo+z2O+BlYE0qggol3NhXERu+aIwxkIJx6CLS\nFOgLPBbDvoNFZKaIzKyoqIjrPOHGxHboAO+/H9ehjDEmJ6ViYtFDwE2qujvajqo6TlU7qWqnRo0a\nxXWS/v1h3DgoKXGt8pISd/+yy2DxYvj880TDN8ZkswMOOACAVatWcd55oS/RnXDCCUQbBv3QQw+x\nJeBCXCzleGNxxx138MADDyR9nFRIRULvBLwgIkuA84BHReTsFBx3P/37w5Il7mLokiXu/gUXQGEh\nPP10Os5ojMkWhxxyyJ5KiokITuixlOOtapJO6KraQlVLVbUUmAhcraqvJh1ZjBo2hD59YPx4qKzM\n1FmNMYkYNmwYjzzyyJ77/tbtpk2bOPnkk/eUun3ttdf2e+6SJUsoKysDYOvWrfTr149WrVrRt2/f\nPeVzAYYMGUKnTp1o06YNI0aMAFzBr1WrVnHiiSdy4oknAvsuYBGqPG6kMr3hzJ07ly5dutCuXTv6\n9u27p6zAmDFj9pTU9RcG+9e//kX79u1p37495eXlEUsixCxcGUb/DXge+B6oBFYAlwNXAVeF2Pcp\n4Lxox9Qky+cGe/VVV9bz9ddTdkhjclJgOdbrrlPt3j21t+uui3z+2bNn6/HHH7/nfqtWrXTZsmVa\nWVmpGzZsUFXViooKPeyww/aUoK1du7aq7lt69y9/+Yteeumlqqo6b948LSgo0M8++0xV95bf3blz\np3bv3l3nzZunqnvL4fpFK48bqUxvoBEjRuj999+vqqpt27bVadOmqarqbbfdptf5XpAmTZrotm3b\nVHVvSd0+ffro9OnTVVV148aNWllZud+xU14+V1UvUtUmqlqoqs1U9X9Vdayqjg2x7yWqmvh3ogT1\n6uVa6tbtYkx2Ky8vZ82aNaxatYp58+ZRr149mjdvjqpyyy230K5dO3r06MHKlSv54Ycfwh7nww8/\nZMCAAQC0a9eOdu3a7XnspZdeokOHDpSXlzN//nwWLFgQMaZw5XEh9jK94AqLrV+/nu7duwMwcOBA\nPvzwwz0x9u/fn/Hjx1O9upvP2a1bN2644QbGjBnD+vXr92xPRpWZKRpJjRrwm9/A2LFWrMuYWPl6\nFjLu/PPPZ+LEiaxevZoLL7wQgAkTJlBRUcGsWbMoLCyktLQ0ZNncaBYvXswDDzzAZ599Rr169bjk\nkksSOo5fcJneaF0u4bz55pt8+OGHvP7664waNYovvviCYcOGcfrpp/PWW2/RrVs3pkyZwlFHHZVw\nrFBFy+eGMnAg7NgBvlWgjDFZ6sILL+SFF15g4sSJnH/++YBr3TZu3JjCwkKmTp3K0qVLIx7j+OOP\n57nnngPgyy+/5HPfMLeff/6Z2rVrU7duXX744QfefvvtPc8JV7o3XHnceNWtW5d69ertad0/++yz\ndO/end27d7N8+XJOPPFE7rvvPjZs2MCmTZv49ttvadu2LTfddBPHHHPMniXykpETLXSA8nIoK3Pd\nLkOGeB2NMSacNm3asHHjRpo2bUqTJk0A6N+/P2eccQZt27alU6dOUVuqQ4YM4dJLL6VVq1a0atWK\njh07AnD00UdTXl7OUUcdRfPmzenWrdue5wwePJiePXtyyCGHMDVgenm48riRulfCefrpp7nqqqvY\nsmULhx56KE8++SS7du1iwIABbNiwAVXlf/7nfzjooIO47bbbmDp1KtWqVaNNmzb06tUr7vMFq7Ll\nc0N54AEYOhS++gqOPDKlhzYmJ1j53Kol3vK5OdPlAm5cerVqdnHUGJOfciqhN2kCPXu6hG5j0o0x\n+SanEjrAVVfBqlXwasamNhlTtXjVzWrik8j7lHMJvXdvaNECxozxOhJjsk+tWrVYt26dJfUsp6qs\nW7eOWrVqxfW8nBnl4ldQANdcA3/4A8ydC745AcYYoFmzZqxYsYJ4q52azKtVqxbNmjWL6zk5NcrF\n76efoFkz6NcP/vd/03IKY4zxRN6McvGrVw8uvtitQ+qrvWOMMTkvJxM6wLXXwvbt8PjjXkdijDGZ\nkbMJvawMTjoJHn0Udu70OhpjjEm/nE3oAL/7HSxfDiFKKxtjTM7J6YR+xhluqbp774Vdu7yOxhhj\n0iunE3pBgUvms2bBY1GXsDbGmKotpxM6uKGLp54Kt9wCK1d6HY0xxqRPzid0EXdhtLISrrvO62iM\nMSZ9cj6hAxx2GNx2G7z8MrzxhtfRGGNMeuRFQgdXCqB1a1cWYPNmr6MxxpjUi5rQReQJEVkjIl+G\neby/iHwuIl+IyL9F5OjUhxnahAlQWupqoJeWuvvh1KgBf/87LFsGd92VqQiNMSZzYmmhPwX0jPD4\nYqC7qrYF7gLGpSCuqCZMgMGDYelSUHU/Bw+OnNSPPRZ++1u3OG6UJQuNMabKiZrQVfVD4McIj/9b\nVX/y3Z0BxFceLEHDh8OWLftu27LFbY/k7rvdhdJbb01fbMYY44VU96FfDrwd7kERGSwiM0VkZrLl\nO5cti2+7X/PmcP31MH48zJ6dVAjGGJNVUpbQReREXEK/Kdw+qjpOVTupaqdGjRoldb7i4vi2Bxo2\nDBo2dBdKrc6/MSZXpCShi0g74HHgLFVdl4pjRjNqFBQV7butqMhtj6ZuXRgxAqZOhbfeSk98xhiT\naUkndBEpBiYBF6vqN8mHFJv+/WHcOFerRcT9HDfObY/FlVdCy5bwxz9aNUZjTG6IumKRiDwPnAA0\nBH4ARgCFAKo6VkQeB84F/ONGdoZbTSNQOlcsitWkSXDuuW4m6ZAhnoZijDExibRiUU4uQRcrVejR\nw10c/eor+OUvPQ3HGGOiyrsl6GLlr/OyZQvccIPX0RhjTHLyOqEDHHmkG/Xy3HPw7rteR2OMMYnL\n+4QOcPPN7gLp1VfDtm1eR2OMMYmxhA7UquW6XhYtgnvu8ToaY4xJjCV0nx493JDHP/0JFi70Ohpj\njImfJfQAo0fDgQfCwIE2Nt0YU/VYQg/QuLFbe/Szz+C++7yOxhhj4mMJPcj557t1SO+8E+bO9Toa\nY4yJnSX0EB5+GBo0cF0v27d7HY0xxsTGEnoIDRrAP/4Bn38OI0d6HY0xxsTGEnoYffrAZZe5US+f\nfup1NMYYE50l9AhGj4YmTVxit64XY0y2s4QeQd26bmHp+fNjq7NujDFesoQexemnw8UXw7332qgX\nY0x2y6mEPmEClJZCtWru54QJqTnuQw+5C6WXXQaVlak5pjHGpFrOJPQJE2DwYFi61NU5X7rU3U9F\nUq9f39V6mTMH7r8/+eMZY0w65MwCF6WlLokHKymBJUtSc44LL4RXX3UzSdu1S80xjTEmHnmxwMWy\nZfFtT8TDD0O9eq5P3Ua9GGOyTc4k9OLi+LYnolEjePxxN+HojjtSd1xjjEmFqAldRJ4QkTUi8mWY\nx0VExojIIhH5XEQ6pD7M6EaNgqKifbcVFaV+uGGfPjBoEPz5z/Dxx6k9tjHGJCOWFvpTQM8Ij/cC\nWvpug4HHkg8rfv37w7hxrs9cxP0cN85tT7XRo93xf/tb2LQp9cc3xphERE3oqvoh8GOEXc4CnlFn\nBnCQiDRJVYDx6N/fXQDdvdv9TEcyB6hTB55+GhYvhhtvTM85jDEmXqnoQ28KLA+4v8K3bT8iMlhE\nZorIzIqKihSc2jvHHeeS+bhxMG2a19EYY0yGL4qq6jhV7aSqnRo1apTJU6fFnXfCYYe58e5bt3od\njTEm36Uioa8Emgfcb+bb5rl0zRz1KypytV7++1+4667UHtsYY+KVioQ+Gfitb7RLF2CDqn6fguMm\nJZ0zRwOdfDJceqkb9TJvXmqPbYwx8Yg6U1REngdOABoCPwAjgEIAVR0rIgI8jBsJswW4VFWjTgFN\n9UzRYJmYOer344/QqpUb8z5jBhQUpPb4xhjjF2mmaPVoT1bVi6I8rsA1CcaWNpmYOepXvz787W+u\nNMBf/wo33JD6cxhjTDQ5M1M0WCZmjgY6/3w480wYPhy+/jo95zDGmEhyNqFnauaonwiMHevOcckl\nsHNnes5jjDHh5GxCz+TMUb8mTVyZ3Rkz4IEH0nceY4wJJWfK52aTCy5wZXZnzYK2bb2OxhiTS/Ki\nfG4s0j0u3e/RR12Z3YEDYceO9JzDGGOC5U1Cz9S4dICGDeEf/3ArHI0cmfrjG2NMKHmT0IcPhy1b\n9t22ZYvbng5nnunWIL3nHqv1YozJjLxJ6Jkcl+43Zgy0bAkDBsC6dek7jzHGQB4l9EyPSweoXRte\neAEqKuDyy11XjzHGpEveJPRMj0v3Ky+HP/0JXnvNjVM3xph0yZuE7sW4dL/rroNeveD3v4cvvkj/\n+Ywx+cnGoWfImjVw9NFuOONnn7nuGGOMiZeNQ88CjRu7IZJffQXXZF0pM2NMLrCEnkEnnQS33+7W\nI336aa+jMcbkGkvoGXbbbXDCCXD11bBggdfRGGNyiSX0DCsocF0vtWu7mi/Bk52MMSZRltA9cMgh\n8OyzMH++LYZhjEmdvE7omSrWFcppp8HQoW6R6Vdeydx5jTG5K28TeiaLdYVz993QsSMMGgQrVmTu\nvMaY3JS3CT3TxbpCqVEDnn8etm939V527crcuY0xuSemhC4iPUXkaxFZJCLDQjxeLCJTRWSOiHwu\nIr1TH2pqeVGsK5SWLeHhh+Ff/3IlAowxJlFRE7qIFACPAL2A1sBFItI6aLdbgZdUtRzoBzya6kBT\nzYtiXeEMHAj9+rkx6vffb0W8jDGJiaWF3hlYpKrfqeoO4AXgrKB9FDjQ93tdYFXqQkwPr4p1hSLi\nFsQ45xz44x/h3HNhw4bMx2GMqdpiSehNgeUB91f4tgW6AxggIiuAt4DfhTqQiAwWkZkiMrOioiKB\ncFPHy2JdoRxwALz0EoweDZMnQ6dO8Pnn3sRijKmaUnVR9CLgKVVtBvQGnhWR/Y6tquNUtZOqdmrU\nqFGKTp24/v1hyRLYvdv99CqZ+4m4ioxTp8LmzdC1K0yZ4m1MxpiqI5aEvhJoHnC/mW9boMuBlwBU\n9ROgFtAwFQHmo+OOg1mz3AXTPn3guee8jsgYUxXEktA/A1qKSAsRqYG76Dk5aJ9lwMkAItIKl9C9\n7VNJgJcTjYI1aeJGvnTr5r45/PWv3sVijKkaoiZ0Vd0JXAtMARbiRrPMF5GRInKmb7cbgStEZB7w\nPHCJelVoPUHZMNEoWN268H//5y6WXn89jBjhXSzGmOxnC1z4lJa6JB6spMT1r3tp1y644gp48kl4\n6ik3zNEYk59sgYsYhJtQtHSp990vBQWu5stJJ7lvDZ984l0sxpjsZQndJ9KEoqVL4dJLoWFD7/rX\nCwvdsMbmzaFvX1i+PPpzjDH5xRK6T6iJRoEqK2HdOm/71xs0cGPUt2yBs8+2WurGmH1ZQvcJnGgU\ni0wX8vJr3doV9JozB668MvPnN8ZkL0voAfwTjWJN6pku5OV3+ulwxx0wfry3ffvGmOxiCT2EaN0v\nfl4U8vK75RY3Rv3qq2HxYu/iMMZkD0voIQTXeWnQwNUuDxRcyCvTk5KqV3ctdICLL4adO9N7PmNM\n9rOEHkZgnZe1a+GJJ8IX8vJqUlJpKTz6KHz8Mdx7b3rPZYzJfjaxKAW8npQ0YAC88MLeUgHGmNxl\nE4vSzOvVjx55xH2onHEGzJuXmXMaY7KPJfQU8Hr1o7p14d13oXZtOOUUWLgwM+c1xmQXS+gJCrwI\numlT9Ium6daiBbz/vounRw/49tvMndsYkx0soScg+CKofwZpgwbern50xBHw3nuwfTucfLIldWPy\njSX0BAwfvv+0+8pKt4yc16sflZXBO+/Azz9Dx47w6qvexGGMyTxL6Anw+iJoNB06wOzZbsWjvn1h\n6FD3gWOMyW2W0BMQy0VQr1c/Ki2F6dPdTNIHHoATToDXXoOtWzMbhzEmcyyhJyBUaYDAi6DZsvpR\nzZpuSOOECfD1165CY+PGcNFF8MorNrvUmFxjCT0BwaUBgi+ChupjT6Y6Y7Kt/d/8Br7/HqZMccn8\nvffcsnZHHAF/+xts3pxYXMaY7GIzRdOgWjXXMg9FxHXNjBoV24VTf2s/8AOiqCi5UTQ7d8Lrr8P9\n97vVj+rXhxtvhJtucqsjGWOyl80UzbBIE4ri7YJJdWsfXGGvvn3h3/92dWCOPdYdr3dv+PHHxI9r\njPFWTAldRHqKyNciskhEhoXZ5wIRWSAi80XkudSGWbXEUn43MClH6lJJ94iaX//aXSx9/HGYNg06\ndYLPP0/NsY0xmRU1oYtIAfAI0AtoDVwkIq2D9mkJ3Ax0U9U2wPVpiLXKCO5jD2fZsugXUDNVVuDy\ny11xr+3boWtXePHF1B7fGJN+sbTQOwOLVPU7Vd0BvACcFbTPFcAjqvoTgKquSW2YVU9g+d1wKyAV\nF0fvUok2oiaVunSBWbOgvBz69YNhw2DXrtSfxxiTHrEk9KZA4BrzK3zbAh0BHCEiH4vIDBHpGepA\nIjJYRGaKyMyKiorEIq6CQiXlwkJXAyZU2V3Y26USbURNqh18MHzwgfuWcN99roLj+vXpOZcxJrVS\ndVG0OtASOAG4CPiHiBwUvJOqjlPVTqraqVGjRik6dfYLtQKSiKsBE05gl0pgaz8TZQVq1IC//x3G\njnVVHDt3tgqOxlQFsST0lUDzgPvNfNsCrQAmq2qlqi4GvsEleOMTmJQPOAB27Ai/b6YrNYZz5ZUw\ndSps2OD61T/4wOuIjDGRxLdbnsAAABS+SURBVJLQPwNaikgLEakB9AMmB+3zKq51jog0xHXBfJfC\nOHNKpBEqsXSpZLKswLHHwqefQrNmcNpp8PTT6TuXMSY51aPtoKo7ReRaYApQADyhqvNFZCQwU1Un\n+x47VUQWALuAoaoaoUMhvxUXJ75kXfBEI/+oGEhfV0xJiRuvft55cMklrizvnXdGHsFjjPGAqnpy\n69ixo+ar8eNVi4pU3UBFdysqctv9j5eUqIq4n/7tqu5+4PP8t5KS9Me9Y4fqZZe5811wgeqmTek/\npzFmX7iGdMi8ajNFPRBp5Eq0celelu4tLHQTkO67DyZOdJOSvrOONWOyhtVyyTKlpZG7Y6I9nilT\nprix6iJuEtIpp2Tu3MbkM6vlUoVEa4FncqJRJKedBjNnQtOm0LMn3HabLaJhjNcsoWeZaFP9Q3XX\nDBzoZpb6R71cfXVmRsEcdpir1jhgANx9t5tpumBBes5ljInOEnqWiaUFHjimfdQoN5QwsM/9scf2\nvX/xxS75pyO5H3CAO//LL7tvER06wIMPutiMMZllCT3LxDvVP1QtmGD+yyTpXDnpnHPgyy/h1FPh\nhhvc+HVrrRuTWXZRtIqLtJhGOOm8gKoK48fD9de7WjXDh7siXzVqpOd8xuQbuyiawxIpo5vOIY4i\nrotn4UI491wYMQKOOQZWr07fOY0xjiX0Ki6WxTSCpbqWeiiNG8Nzz8HkyW5maY8esHZt+s9rTD6z\nhF7FhepzHzJkbw324On5mR7ieMYZbv3Sb791/es//ZS5cxuTbyyh54Dg8rqPPup+qsKzz2aulno4\nJ54Ir7wC8+dDr16wcWNmz29MvrCEnuOSraWeqsqOPXvCSy+5FZFOOQWWL4/+HGNMfCyhm7Ci1ZWJ\n11lnuaQ+fz4cfTRMmpTaeE3VkckS0PnEErrZR+B/tIEDI693moi+fWHOHDj8cDcKZsgQ2Lo1qZBN\nFZPqhoLZyxK62SP4P1q4BaKTHfZ4+OEwfTr88Y9umbsuXWDx4uSOaaqOaAujm8RZQs8zkb7qxjLr\nFFIz7LFGDVeG9+233QfEMce45e5M7vOyBHSus4SeR0J91b30UmjY0CX4UGV5g6V62GPPnm6Ju8aN\n3cXSRx7Zd+br7t2upMDjj8OgQdCtm5usZBdVq65oBehM4iyh55FQLfDKSli3LnL5gIKC8JUdU9Hv\n2bIlzJgBvXvDtddC/fpQty7Urg01a0LbtnDFFW7oY2Ul3HWXO/cZZ8Cbb8Zf+sB4K1tKQOciS+h5\nJJGvtEVFrppiuMqOgS38aAk+UnfPgQfCq6/CmDGuHO9ll7kywEOHunN+/bWbafrpp26VpJtvdvXY\n+/RxC21s2BD/32a8EW8BOhOHcGvTBd6AnsDXwCJgWIT9zgUU6BTtmPm8pqhXwq1HGuoWz3qmsayN\n2qCBao0a4fdNxI4dqvfco1pQoNqiheqMGYkfy5iqgghrisaSzAuAb4FDgRrAPKB1iP3qAB8CMyyh\nZ6dQi1PHs+C0SGwfBv4PgmTOFY9//9sdp3p11VGjVDdvTv6YxmSrSAk9li6XzsAiVf1OVXcALwBn\nhdjvLuA+YFsi3xRM+gV/1W3QYP+ytpH6MmO9aLVsWewjZlIxsqFrV5g7F84+2523tNT9DVY3xuSb\nWBJ6UyBwTMEK37Y9RKQD0FxV30xhbCYNAksBrF0LTzwRe19mrJUdi4tjT9TxjGyI1Ad/0EHwz3/C\nRx9B585w663u2MOH28Qlk0fCNd39N+A84PGA+xcDDwfcrwZMA0p996cRpssFGAzMBGYWFxdn6AuK\nSaVo/eL+bpmCgvj622M5b3AXTqTnz5un2q+f2+/ww1WnTUvZS2CMp0iyy2Ul0DzgfjPfNr86QBkw\nTUSWAF2AySKy34oaqjpOVTupaqdGjRrF9oljskq4Fj64Vr76hhCGmmVaWOi6eRIZ2RDv7MJ27eD5\n5+H9912sJ5zgygxYTXaTy2JJ6J8BLUWkhYjUAPoBk/0PquoGVW2oqqWqWoq7KHqmqtr6cnnAn+BL\nSkKPBw8cw/7kky6h+is/QuwFmsJ14SxdGvm5J50En38Ov/89/P3v0KgRNGsGp50GN94ITz3lasts\n3x7rX2xM9qoebQdV3Ski1wJTcCNenlDV+SIyEtf0nxz5CCYfhEu4u3e7WzD/rFV/q9tfoAlCt9qL\ni8PPZA313AkTXOt92TL33FGjYPZseOcdN/N0/nxXN36b7xJ+9epw5JFuMtPOne4mAmVlrk++c2do\n3x5q1Yrt9UhUqLhtfLaJlS0SbVKitDR0wg23IHW8+wd/AITif26ofYuK9u/i2bULFi2CefPcKJn5\n82HHDpfcq1d3v8+dC6tWuf1r14Y774TrrnOPp1qscZv8FmmR6KgXRdN1s3HouSXei5bhxrSL7HtM\n/wXYkhLVIUMiT27yPzfcPomOeV+xQnXSJNXTT3fHad9e9T//SexYkaQ6bpObSGZiUbpultBzT3AC\njjSCJVzyKiiIPrM02nOjJfxE7d6tOnGi6iGHuGNdcYXqnDnJHTNQLB9yxkRK6FbLxaRMPMvdhRvT\nvmuXS2Pr1rkuj0D+US3RnhtOstX8RNyiHAsXwu9+52rMlJe7vvWHHkp+BI1VIUyMrX4UIFymT/fN\nWugmsEUfy7j1wNZqvM9Ntm5MKGvXqj78sGqnTu4cdeqo/uUvrsZMIuLttjL5+ZphXS4m28VTJyae\n58bS/RNNLF1J8+ap9urlztmmjerUqek7V7bIhljz8bpDpIRuo1xMVgg36iVQuBEf8Y6YiUc8I09U\nYfJkuP56d94OHdxQyJYt3a2sDFq33r9+TlWULSNyqlUL3c0mEnq4bC6wUS4m64X66lxY6C6ORmsB\nxvK1O9HWZCItwC1bXNXHU05RLS3d9xtE9eqq7dqp/va3qg89pDp9uuqmTbHFkk2ypWWcLXFkEtbl\nYqqCZL7CR3puIh8WkUbTxDvyZNs21fnzVV98UfXmm13XzMEH7z1WtWouyY8ZU3WSe7aMyLE+dEvo\nJs8ksjBHtFru/iGSyfQdr1ypOnmy6u23q3bp4o5bv77qrbeqrl6dqr8+PbKpZZwNffmZZAnd5LV4\nL7jGs7JTKluEH3+sevbZLt6aNVUHDVL905+yM1nlY8s4Fpn4cLGEbvJarAna310Q6QMg3BDJVLZM\nv/pK9corXbdQuj48UiHfWsbRZOpDLlJCt4lFJufFszBH4M9gJSXhR04sXRp+Yku8E1+OPBLGjoVf\n/nL/x7ZscYtnjx8PL78Mb7wB773nas6sX7///s88A82bu1EfzZu7USixrCQVi3gmkuWDeEs8p4MN\nWzR5IbCKYf36sHHjvjNRCwvhwAPhxx9DP+4fkjd8ePThlbEeK1oCDDckL5IDD3QfSJWVsHIlbNoU\ner+yMujeHY4/3v0M9eFh4pOpIZSRhi1aQjd5KZ4EH1jGNpaqj7GIZYx8uPH1zZu7Vvn27e62dSus\nWeOOt2SJ+5tq1oS33w6d0OvWhV/9Cj7+GDZvdtvatXM14k87DQ4/3JU3mD8fFixwi5JcdRUcemhy\nf3M8qmIZ4XTOhwhk49CNiSDeERuBfcfxXDyNd3hfsn2y0YYW7tjhqkbee6/qCSeE7rNv3NiNnRdR\nPess1Q8+cEXK0qmqXnDNhj50S+gm7yUzpjreETHxXkRN5sJjvB9UGzeqvv666tixqv/6l6tVo+rK\nB99yixu3D6pdu6rOmBF7HPHKpiGR8bJRLsZ4LJkEEsuY9eBbrDNgk5XqFuOWLS7Z+ydF9e+vumxZ\namNWTf2kpVwbjWMJ3ZgIkk18gQkjVB33wAQe6nF/AktHsklHMvv5Z9dir1lT9Re/cEk+lVLZQq+q\n3TeRWEI3JopUJr5Ix4rWRZPNySb473rwQdXTTnNx33CD6s6dqTtPqpJwurtvvGj9W0I3JkvEciE1\nG/uKwyXZp59WvfZad/+ss/bWogm3fGCsiS9ViTKdNWe8av0nndCBnsDXwCJgWIjHbwAWAJ8D7wMl\n0Y5pCd3ko1guokZKNpn6JhFr3P4Pn7/+1RUZ69hR9Y47XFdMNnwTSWcL3auLt0kldKAA+BY4FKgB\nzANaB+1zIlDk+30I8GK041pCN/kolouokYZLJlpiOJZjJbuo9+uvq9atG/0DK5HEF1j9slEj1Q4d\n3LWIbt1cGeIVK/bfN9ratMnyquJksgm9KzAl4P7NwM0R9i8HPo52XEvoJl8FJqfgpBAp2cTSuo+U\n4GNZti9cFclYWqPjx6s2bx57Qg9MfJG+LTzzjLsAG/z8E09Ubdt27/3u3VXvvjt1H3qqql9/7Y55\n/PGqZWXu+fXru/H5deok9kG1e3fiyxSqJp/QzwMeD7h/MfBwhP0fBm4N89hgYCYws7i4OPG/yJgc\nEU+3RyITmfwfEMkOr4zW0k3k+P7EF+q5tWqpXnWVGxpZrVrk5y9cqDpy5L415uNJssHvwRNPuCqX\n7drtfX6nTqp9+7qFSa65RvW880J/KIb6QN69W/Wbb1THjXN/T7NmbgGURGUsoQMDgBlAzWjHtRa6\nMfFJZhJTos+NtaUb7/GrVXNJcdKkvROWQt0aNgz/WHDXxrp1se0brUvG/8H561+7kTzhxtp//73q\nuefuTeyFhaq///3embSrV7tZuIcdtvfYBx6498Mr0WsgGelyAXoAC4HG0Y6pltCNiVsirWB/gkqm\nTEEsLd1Ix/ePciku3pvUSktjO9/OneE/LEJ1D4Xbt0ED188e62vYuHHs70tlpRvtc/jh7rnl5e7D\nyl9KoXt31cceU/3zn/e/WJxIf36yCb068B3QIuCiaJugfcp9F05bRjue/2YJ3Zj4RWtdhkuo0ZJi\nuD71aK1iv0RGfKxZozprlmrTppGfG0sSjrVrKda/0/+3xtOKrqxUfeop1yKvX9+11hcuTO41CiUV\nwxZ7A9/4kvZw37aRwJm+398DfgDm+m6Tox3TEroxyYt1REe0US2xtlzjGYETa+sz3kW+oy0yEtwn\n/swz7oPjoYdiT+aRXqdYrnmEKmCWqlExNrHImDwRbbHsSMko2eF+yYyRT8XF4XQXU0t2IlHWtNDT\ncbOEbkx2y9aiVqkuphZ4sTda90syCTlVM0sjJXRbgs4YE1K2LjEXaknBoiK3PZr+/d1qUSUlbiWh\nkhJ48klYu9b9nSUloZ9XXOwW2wgl3HbYd/nB4cNh4MB9zx3LylVxCZfp032zFroxJlHp+vYQqRUd\nbws9XbVeiNBCtyXojDEmQPDyd717w1tvueXlRFxq9ou0Pmy6lqSLtASddbkYY0yAwK6mUaPg6af3\nJmZVl9QhepdJIl00yaqevkMbY0zVNnz4/guCq8bWyi4uDt1CLy5OWXj7sRa6McaEkUwrO5mLt4my\nhG6MMWGEa03H0soONaIm5aNaglhCN8aYMJJtZWd66KcldGOMCcOLVnYy7KKoMcZE0L9/9ibwYNZC\nN8aYHGEJ3RhjcoQldGOMyRGW0I0xJkdYQjfGmBzhWXEuEakAQkyMjUlDYG0Kw0mlbI0tW+MCiy0R\n2RoXZG9s2RoXxBdbiao2CvWAZwk9GSIyM1y1Ma9la2zZGhdYbInI1rgge2PL1rggdbFZl4sxxuQI\nS+jGGJMjqmpCH+d1ABFka2zZGhdYbInI1rgge2PL1rggRbFVyT50Y4wx+6uqLXRjjDFBLKEbY0yO\nqHIJXUR6isjXIrJIRIZ5HMsTIrJGRL4M2FZfRN4Vkf/6ftbzIK7mIjJVRBaIyHwRuS4bYhORWiLy\nqYjM88V1p297CxH5j+89fVFEamQyrqAYC0Rkjoi8kU2xicgSEflCROaKyEzftmz4t3aQiEwUka9E\nZKGIdM2SuI70vVb+288icn2WxPZ737//L0Xked//i5T8O6tSCV1ECoBHgF5Aa+AiEWntYUhPAT2D\ntg0D3lfVlsD7vvuZthO4UVVbA12Aa3yvk9exbQdOUtWjgfZATxHpAtwHPKiqhwM/AZdnOK5A1wEL\nA+5nU2wnqmr7gPHKXr+fAH8F/k9VjwKOxr12nselql/7Xqv2QEdgC/CK17GJSFPgf4BOqloGFAD9\nSNW/M1WtMjegKzAl4P7NwM0ex1QKfBlw/2ugie/3JsDXWfC6vQackk2xAUXAbOBXuBly1UO9xxmO\nqRnuP/lJwBuAZFFsS4CGQds8fT+BusBifIMrsiWuEHGeCnycDbEBTYHlQH3cehRvAKel6t9ZlWqh\ns/fF8Fvh25ZNfqmq3/t+Xw380stgRKQUKAf+QxbE5uvSmAusAd4FvgXWq+pO3y5evqcPAX8Edvvu\nNyB7YlPgHRGZJSKDfdu8fj9bABXAk75uqsdFpHYWxBWsH/C873dPY1PVlcADwDLge2ADMIsU/Tur\nagm9SlH3cevZuFAROQB4GbheVX8OfMyr2FR1l7qvwc2AzsBRmY4hFBHpA6xR1VlexxLGsaraAdfd\neI2IHB/4oEfvZ3WgA/CYqpYDmwnqwsiC/wM1gDOBfwY/5kVsvj77s3AfhocAtdm/2zZhVS2hrwSa\nB9xv5tuWTX4QkSYAvp9rvAhCRApxyXyCqk7KptgAVHU9MBX39fIgEfEvh+jVe9oNOFNElgAv4Lpd\n/polsflbdqjqGlxfcGe8fz9XACtU9T+++xNxCd7ruAL1Amar6g+++17H1gNYrKoVqloJTML920vJ\nv7OqltA/A1r6rgjXwH2VmuxxTMEmAwN9vw/E9V9nlIgI8L/AQlUdnS2xiUgjETnI9/svcP36C3GJ\n/Tyv4gJQ1ZtVtZmqluL+XX2gqv2zITYRqS0idfy/4/qEv8Tj91NVVwPLReRI36aTgQVexxXkIvZ2\nt4D3sS0DuohIke//qf81S82/My8vViR4UaE38A2u73W4x7E8j+sHq8S1Vi7H9bu+D/wXeA+o70Fc\nx+K+Sn4OzPXdensdG9AOmOOL60vgdt/2Q4FPgUW4r8Y1PX5fTwDeyJbYfDHM893m+//de/1++mJo\nD8z0vaevAvWyIS5fbLWBdUDdgG2exwbcCXzl+z/wLFAzVf/ObOq/McbkiKrW5WKMMSYMS+jGGJMj\nLKEbY0yOsIRujDE5whK6McbkCEvoxhiTIyyhG2NMjvh/4cyVXc5bC9MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-69lsZ3kyCIp",
        "colab_type": "code",
        "outputId": "0862b3cd-0533-4631-96ec-92a2d4a0c00b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.evaluate(x_test, y_test, batch_size=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11919387721767029, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}